{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('data/ner_dataset.csv', encoding='latin1')\n",
    "data = data.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Thousands</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demonstrators</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>have</td>\n",
       "      <td>VBP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>marched</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>through</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>London</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>protest</td>\n",
       "      <td>VB</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>war</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>Iraq</td>\n",
       "      <td>NNP</td>\n",
       "      <td>B-geo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>and</td>\n",
       "      <td>CC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>demand</td>\n",
       "      <td>VB</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>withdrawal</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>British</td>\n",
       "      <td>JJ</td>\n",
       "      <td>B-gpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>troops</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>from</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>that</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>country</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Sentence: 1</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>Families</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>of</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>soldiers</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>killed</td>\n",
       "      <td>VBN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>in</td>\n",
       "      <td>IN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Sentence: 2</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sentence #           Word  POS    Tag\n",
       "0   Sentence: 1      Thousands  NNS      O\n",
       "1   Sentence: 1             of   IN      O\n",
       "2   Sentence: 1  demonstrators  NNS      O\n",
       "3   Sentence: 1           have  VBP      O\n",
       "4   Sentence: 1        marched  VBN      O\n",
       "5   Sentence: 1        through   IN      O\n",
       "6   Sentence: 1         London  NNP  B-geo\n",
       "7   Sentence: 1             to   TO      O\n",
       "8   Sentence: 1        protest   VB      O\n",
       "9   Sentence: 1            the   DT      O\n",
       "10  Sentence: 1            war   NN      O\n",
       "11  Sentence: 1             in   IN      O\n",
       "12  Sentence: 1           Iraq  NNP  B-geo\n",
       "13  Sentence: 1            and   CC      O\n",
       "14  Sentence: 1         demand   VB      O\n",
       "15  Sentence: 1            the   DT      O\n",
       "16  Sentence: 1     withdrawal   NN      O\n",
       "17  Sentence: 1             of   IN      O\n",
       "18  Sentence: 1        British   JJ  B-gpe\n",
       "19  Sentence: 1         troops  NNS      O\n",
       "20  Sentence: 1           from   IN      O\n",
       "21  Sentence: 1           that   DT      O\n",
       "22  Sentence: 1        country   NN      O\n",
       "23  Sentence: 1              .    .      O\n",
       "24  Sentence: 2       Families  NNS      O\n",
       "25  Sentence: 2             of   IN      O\n",
       "26  Sentence: 2       soldiers  NNS      O\n",
       "27  Sentence: 2         killed  VBN      O\n",
       "28  Sentence: 2             in   IN      O\n",
       "29  Sentence: 2            the   DT      O"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set(data.Word.tolist())\n",
    "vocab_size = len(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter:\n",
    "    def __init__(self, data):\n",
    "        self.pos = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        \n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s.Word.tolist(),\n",
    "                                                          s.POS.tolist(),\n",
    "                                                          s.Tag.tolist())]\n",
    "        \n",
    "        self.grouped = self.data.groupby('Sentence #').apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "\n",
    "    def reset(self):\n",
    "        self.pos = 1\n",
    "        \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped['Sentence: {}'.format(self.pos)]\n",
    "            self.pos += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "getter = SentenceGetter(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent = getter.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Thousands', 'NNS', 'O'), ('of', 'IN', 'O'), ('demonstrators', 'NNS', 'O'), ('have', 'VBP', 'O'), ('marched', 'VBN', 'O'), ('through', 'IN', 'O'), ('London', 'NNP', 'B-geo'), ('to', 'TO', 'O'), ('protest', 'VB', 'O'), ('the', 'DT', 'O'), ('war', 'NN', 'O'), ('in', 'IN', 'O'), ('Iraq', 'NNP', 'B-geo'), ('and', 'CC', 'O'), ('demand', 'VB', 'O'), ('the', 'DT', 'O'), ('withdrawal', 'NN', 'O'), ('of', 'IN', 'O'), ('British', 'JJ', 'B-gpe'), ('troops', 'NNS', 'O'), ('from', 'IN', 'O'), ('that', 'DT', 'O'), ('country', 'NN', 'O'), ('.', '.', 'O')]\n"
     ]
    }
   ],
   "source": [
    "print(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features\n",
    "\n",
    "\n",
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [label for token, postag, label in sent]\n",
    "\n",
    "def sent2tokens(sent):\n",
    "    return [token for token, postag, label in sent]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [sent2features(s) for s in sentences]\n",
    "y = [sent2labels(s) for s in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn_crfsuite import CRF\n",
    "\n",
    "crf = CRF(algorithm='lbfgs',\n",
    "          c1=0.1,\n",
    "          c2=0.1,\n",
    "          max_iterations=100,\n",
    "          all_possible_transitions=False,\n",
    "          verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_predict\n",
    "from sklearn_crfsuite.metrics import flat_classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred = cross_val_predict(estimator=crf, X=X, y=y, cv=5, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|██████████| 47959/47959 [00:17<00:00, 2779.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 0\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 152663\n",
      "Seconds required: 3.983\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.100000\n",
      "c2: 0.100000\n",
      "num_memories: 6\n",
      "max_iterations: 100\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "Iter 1   time=3.30  loss=1685559.31 active=151597 feature_norm=1.00\n",
      "Iter 2   time=3.39  loss=1321251.59 active=149864 feature_norm=4.40\n",
      "Iter 3   time=1.72  loss=1032583.16 active=143571 feature_norm=3.85\n",
      "Iter 4   time=8.45  loss=567601.33 active=145448 feature_norm=3.24\n",
      "Iter 5   time=1.69  loss=475669.88 active=147274 feature_norm=4.08\n",
      "Iter 6   time=1.68  loss=369032.77 active=145972 feature_norm=5.87\n",
      "Iter 7   time=1.68  loss=320589.25 active=138308 feature_norm=7.20\n",
      "Iter 8   time=1.69  loss=285565.86 active=132252 feature_norm=8.19\n",
      "Iter 9   time=1.68  loss=246725.43 active=123606 feature_norm=10.38\n",
      "Iter 10  time=1.68  loss=223990.57 active=120232 feature_norm=11.67\n",
      "Iter 11  time=1.69  loss=206643.81 active=117767 feature_norm=13.04\n",
      "Iter 12  time=1.68  loss=193344.06 active=114532 feature_norm=14.38\n",
      "Iter 13  time=1.69  loss=184406.19 active=111262 feature_norm=15.81\n",
      "Iter 14  time=1.69  loss=171994.93 active=110885 feature_norm=16.23\n",
      "Iter 15  time=1.70  loss=160600.32 active=108620 feature_norm=17.73\n",
      "Iter 16  time=1.70  loss=152142.28 active=107794 feature_norm=18.94\n",
      "Iter 17  time=1.69  loss=144642.80 active=106945 feature_norm=20.77\n",
      "Iter 18  time=1.70  loss=138056.10 active=106318 feature_norm=22.29\n",
      "Iter 19  time=1.70  loss=131443.49 active=105279 feature_norm=24.12\n",
      "Iter 20  time=1.69  loss=123214.10 active=103293 feature_norm=26.56\n",
      "Iter 21  time=1.70  loss=116317.33 active=101508 feature_norm=31.02\n",
      "Iter 22  time=1.69  loss=109680.07 active=101937 feature_norm=32.78\n",
      "Iter 23  time=1.70  loss=104831.75 active=100866 feature_norm=35.68\n",
      "Iter 24  time=1.70  loss=101942.02 active=97535 feature_norm=43.70\n",
      "Iter 25  time=1.70  loss=94446.76 active=98068 feature_norm=45.43\n",
      "Iter 26  time=1.72  loss=91778.74 active=97950 feature_norm=47.13\n",
      "Iter 27  time=1.70  loss=86023.00 active=95558 feature_norm=54.96\n",
      "Iter 28  time=3.38  loss=84316.45 active=95798 feature_norm=57.86\n",
      "Iter 29  time=1.70  loss=81142.10 active=95607 feature_norm=61.41\n",
      "Iter 30  time=1.70  loss=78502.15 active=95146 feature_norm=65.10\n",
      "Iter 31  time=1.70  loss=75684.65 active=93366 feature_norm=72.06\n",
      "Iter 32  time=1.70  loss=73442.77 active=93447 feature_norm=74.37\n",
      "Iter 33  time=1.69  loss=71216.11 active=92765 feature_norm=78.93\n",
      "Iter 34  time=1.70  loss=68543.02 active=91710 feature_norm=87.13\n",
      "Iter 35  time=1.69  loss=66509.14 active=91343 feature_norm=92.15\n",
      "Iter 36  time=1.70  loss=64869.20 active=91186 feature_norm=96.79\n",
      "Iter 37  time=1.70  loss=62582.68 active=89063 feature_norm=106.42\n",
      "Iter 38  time=1.71  loss=61455.96 active=87478 feature_norm=114.68\n",
      "Iter 39  time=1.70  loss=59637.77 active=87597 feature_norm=119.10\n",
      "Iter 40  time=1.69  loss=58182.50 active=87275 feature_norm=127.11\n",
      "Iter 41  time=1.70  loss=56436.71 active=86974 feature_norm=136.33\n",
      "Iter 42  time=1.69  loss=54506.24 active=86178 feature_norm=150.25\n",
      "Iter 43  time=1.69  loss=53268.02 active=85628 feature_norm=164.17\n",
      "Iter 44  time=1.70  loss=52077.78 active=85836 feature_norm=169.19\n",
      "Iter 45  time=1.70  loss=51135.80 active=85452 feature_norm=176.88\n",
      "Iter 46  time=1.69  loss=50068.34 active=83969 feature_norm=186.81\n",
      "Iter 47  time=1.69  loss=49251.88 active=83545 feature_norm=194.00\n",
      "Iter 48  time=1.70  loss=48583.48 active=82775 feature_norm=202.38\n",
      "Iter 49  time=1.69  loss=48054.59 active=82059 feature_norm=207.61\n",
      "Iter 50  time=1.69  loss=47629.52 active=81592 feature_norm=212.17\n",
      "Iter 51  time=1.69  loss=47391.35 active=79982 feature_norm=219.35\n",
      "Iter 52  time=1.70  loss=46984.33 active=79580 feature_norm=221.32\n",
      "Iter 53  time=1.70  loss=46821.61 active=78999 feature_norm=223.03\n",
      "Iter 54  time=1.69  loss=46474.23 active=77777 feature_norm=228.24\n",
      "Iter 55  time=3.38  loss=46370.38 active=78027 feature_norm=227.87\n",
      "Iter 56  time=1.70  loss=46238.03 active=78230 feature_norm=228.03\n",
      "Iter 57  time=1.71  loss=46090.01 active=77907 feature_norm=228.46\n",
      "Iter 58  time=1.73  loss=45851.74 active=77282 feature_norm=228.78\n",
      "Iter 59  time=1.77  loss=45675.00 active=76713 feature_norm=229.17\n",
      "Iter 60  time=1.74  loss=45537.17 active=76417 feature_norm=229.27\n",
      "Iter 61  time=1.83  loss=45392.94 active=75827 feature_norm=229.58\n",
      "Iter 62  time=1.71  loss=45253.14 active=75492 feature_norm=229.88\n",
      "Iter 63  time=1.72  loss=45125.10 active=75219 feature_norm=230.58\n",
      "Iter 64  time=1.71  loss=45009.29 active=74941 feature_norm=231.25\n",
      "Iter 65  time=1.73  loss=44891.12 active=74588 feature_norm=232.19\n",
      "Iter 66  time=1.69  loss=44787.34 active=74277 feature_norm=232.90\n",
      "Iter 67  time=1.70  loss=44693.62 active=73969 feature_norm=233.75\n",
      "Iter 68  time=1.70  loss=44609.95 active=73707 feature_norm=234.27\n",
      "Iter 69  time=1.69  loss=44521.34 active=73365 feature_norm=234.88\n",
      "Iter 70  time=1.70  loss=44441.71 active=72884 feature_norm=235.38\n",
      "Iter 71  time=1.71  loss=44374.33 active=72602 feature_norm=235.90\n",
      "Iter 72  time=1.69  loss=44306.62 active=72511 feature_norm=236.12\n",
      "Iter 73  time=1.71  loss=44247.36 active=72222 feature_norm=236.43\n",
      "Iter 74  time=1.71  loss=44183.92 active=72055 feature_norm=236.58\n",
      "Iter 75  time=1.71  loss=44131.77 active=71850 feature_norm=236.85\n",
      "Iter 76  time=1.70  loss=44084.86 active=71666 feature_norm=236.95\n",
      "Iter 77  time=1.69  loss=44040.91 active=71479 feature_norm=237.11\n",
      "Iter 78  time=1.69  loss=43997.31 active=71318 feature_norm=237.19\n",
      "Iter 79  time=1.69  loss=43958.18 active=71095 feature_norm=237.36\n",
      "Iter 80  time=1.69  loss=43920.33 active=70948 feature_norm=237.45\n",
      "Iter 81  time=1.69  loss=43884.63 active=70853 feature_norm=237.66\n",
      "Iter 82  time=1.69  loss=43851.03 active=70774 feature_norm=237.72\n",
      "Iter 83  time=1.69  loss=43823.37 active=70615 feature_norm=237.90\n",
      "Iter 84  time=1.70  loss=43795.94 active=70505 feature_norm=237.99\n",
      "Iter 85  time=1.69  loss=43769.00 active=70390 feature_norm=238.19\n",
      "Iter 86  time=1.69  loss=43743.21 active=70338 feature_norm=238.28\n",
      "Iter 87  time=1.70  loss=43716.44 active=70276 feature_norm=238.47\n",
      "Iter 88  time=1.75  loss=43694.72 active=70185 feature_norm=238.56\n",
      "Iter 89  time=1.73  loss=43670.22 active=70109 feature_norm=238.76\n",
      "Iter 90  time=1.74  loss=43648.93 active=70037 feature_norm=238.87\n",
      "Iter 91  time=1.73  loss=43624.71 active=69941 feature_norm=239.09\n",
      "Iter 92  time=1.71  loss=43604.70 active=69895 feature_norm=239.20\n",
      "Iter 93  time=1.71  loss=43582.64 active=69791 feature_norm=239.40\n",
      "Iter 94  time=1.71  loss=43561.86 active=69751 feature_norm=239.51\n",
      "Iter 95  time=1.70  loss=43542.86 active=69697 feature_norm=239.71\n",
      "Iter 96  time=1.70  loss=43524.34 active=69678 feature_norm=239.84\n",
      "Iter 97  time=1.71  loss=43505.67 active=69611 feature_norm=240.04\n",
      "Iter 98  time=1.70  loss=43485.40 active=69571 feature_norm=240.16\n",
      "Iter 99  time=1.71  loss=43469.55 active=69487 feature_norm=240.34\n",
      "Iter 100 time=1.72  loss=43450.13 active=69475 feature_norm=240.46\n",
      "L-BFGS terminated with the maximum number of iterations\n",
      "Total seconds required for training: 183.600\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 69475 (152663)\n",
      "Number of active attributes: 34335 (101626)\n",
      "Number of active labels: 17 (17)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.210\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None,\n",
       "  all_possible_transitions=False, averaging=None, c=None, c1=0.1, c2=0.1,\n",
       "  calibration_candidates=None, calibration_eta=None,\n",
       "  calibration_max_trials=None, calibration_rate=None,\n",
       "  calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "  gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "  max_linesearch=None, min_freq=None, model_filename=None,\n",
       "  num_memories=None, pa_type=None, period=None, trainer_cls=None,\n",
       "  variance=None, verbose=True)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      B-art       0.93      0.73      0.82       402\n",
      "      B-eve       0.85      0.69      0.76       308\n",
      "      B-geo       0.91      0.95      0.93     37644\n",
      "      B-gpe       0.98      0.95      0.97     15870\n",
      "      B-nat       0.90      0.60      0.72       201\n",
      "      B-org       0.91      0.85      0.88     20143\n",
      "      B-per       0.94      0.93      0.94     16990\n",
      "      B-tim       0.96      0.92      0.94     20333\n",
      "      I-art       0.94      0.77      0.85       297\n",
      "      I-eve       0.87      0.67      0.76       253\n",
      "      I-geo       0.90      0.92      0.91      7414\n",
      "      I-gpe       0.96      0.69      0.80       198\n",
      "      I-nat       0.95      0.71      0.81        51\n",
      "      I-org       0.94      0.93      0.94     16784\n",
      "      I-per       0.94      0.96      0.95     17251\n",
      "      I-tim       0.94      0.88      0.91      6528\n",
      "          O       1.00      1.00      1.00    887908\n",
      "\n",
      "avg / total       0.99      0.99      0.99   1048575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = crf.predict(X)\n",
    "report = flat_classification_report(y_pred=pred, y_true=y)\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
