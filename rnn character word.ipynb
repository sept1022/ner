{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "data = pd.read_csv('data/ner_dataset.csv', encoding='latin1')\n",
    "data = data.fillna(method='ffill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SentenceGetter:\n",
    "    def __init__(self, data):\n",
    "        self.pos = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        \n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s.Word.tolist(),\n",
    "                                                          s.POS.tolist(),\n",
    "                                                          s.Tag.tolist())]\n",
    "        \n",
    "        self.grouped = self.data.groupby('Sentence #').apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "\n",
    "    def reset(self):\n",
    "        self.pos = 1\n",
    "        \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped['Sentence: {}'.format(self.pos)]\n",
    "            self.pos += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence #</th>\n",
       "      <th>Word</th>\n",
       "      <th>POS</th>\n",
       "      <th>Tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1048565</th>\n",
       "      <td>Sentence: 47958</td>\n",
       "      <td>impact</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048566</th>\n",
       "      <td>Sentence: 47958</td>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048567</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>Indian</td>\n",
       "      <td>JJ</td>\n",
       "      <td>B-gpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048568</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>forces</td>\n",
       "      <td>NNS</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048569</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>said</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048570</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>they</td>\n",
       "      <td>PRP</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048571</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>responded</td>\n",
       "      <td>VBD</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048572</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>to</td>\n",
       "      <td>TO</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048573</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>the</td>\n",
       "      <td>DT</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048574</th>\n",
       "      <td>Sentence: 47959</td>\n",
       "      <td>attack</td>\n",
       "      <td>NN</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Sentence #       Word  POS    Tag\n",
       "1048565  Sentence: 47958     impact   NN      O\n",
       "1048566  Sentence: 47958          .    .      O\n",
       "1048567  Sentence: 47959     Indian   JJ  B-gpe\n",
       "1048568  Sentence: 47959     forces  NNS      O\n",
       "1048569  Sentence: 47959       said  VBD      O\n",
       "1048570  Sentence: 47959       they  PRP      O\n",
       "1048571  Sentence: 47959  responded  VBD      O\n",
       "1048572  Sentence: 47959         to   TO      O\n",
       "1048573  Sentence: 47959        the   DT      O\n",
       "1048574  Sentence: 47959     attack   NN      O"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words: 35178 tags: 17\n"
     ]
    }
   ],
   "source": [
    "words = set(data.Word.tolist())\n",
    "n_words = len(words)\n",
    "\n",
    "tags = set(data.Tag.tolist())\n",
    "n_tags = len(tags)\n",
    "\n",
    "print('words: {n_words} tags: {n_tags}'.format(n_words=n_words, n_tags=n_tags))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "getter = SentenceGetter(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Thousands', 'NNS', 'O'),\n",
       " ('of', 'IN', 'O'),\n",
       " ('demonstrators', 'NNS', 'O'),\n",
       " ('have', 'VBP', 'O'),\n",
       " ('marched', 'VBN', 'O'),\n",
       " ('through', 'IN', 'O'),\n",
       " ('London', 'NNP', 'B-geo'),\n",
       " ('to', 'TO', 'O'),\n",
       " ('protest', 'VB', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('war', 'NN', 'O'),\n",
       " ('in', 'IN', 'O'),\n",
       " ('Iraq', 'NNP', 'B-geo'),\n",
       " ('and', 'CC', 'O'),\n",
       " ('demand', 'VB', 'O'),\n",
       " ('the', 'DT', 'O'),\n",
       " ('withdrawal', 'NN', 'O'),\n",
       " ('of', 'IN', 'O'),\n",
       " ('British', 'JJ', 'B-gpe'),\n",
       " ('troops', 'NNS', 'O'),\n",
       " ('from', 'IN', 'O'),\n",
       " ('that', 'DT', 'O'),\n",
       " ('country', 'NN', 'O'),\n",
       " ('.', '.', 'O')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences = getter.sentences\n",
    "sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 75\n",
    "max_len_char = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx = {w: i + 2 for i, w in enumerate(words)}\n",
    "word2idx[\"UNK\"] = 1\n",
    "word2idx[\"PAD\"] = 0\n",
    "idx2word = {i: w for w, i in word2idx.items()}\n",
    "tag2idx = {t: i + 1 for i, t in enumerate(tags)}\n",
    "tag2idx[\"PAD\"] = 0\n",
    "idx2tag = {i: w for w, i in tag2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = set([c for w in words for c in w])\n",
    "n_chars = len(chars)\n",
    "char2idx = {c:i+2 for i, c in enumerate(chars)}\n",
    "char2idx['PAD'] = 0\n",
    "char2idx['UNK'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_char = []\n",
    "for sentence in sentences:\n",
    "    sent_sequence = []\n",
    "    for i in range(max_len):\n",
    "        char_sequence = []\n",
    "        for j in range(max_len_char):\n",
    "            try:\n",
    "                char_sequence.append(char2idx[sentence[i][0][j]])\n",
    "            except:\n",
    "                char_sequence.append(char2idx['PAD'])\n",
    "        sent_sequence.append(char_sequence)   \n",
    "    X_char.append(np.array(sent_sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[44, 60, 40, 80, 14, 88, 56, 71, 14,  0],\n",
       "       [40, 85,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [71, 27, 76, 40, 56, 14, 67, 92, 88, 67],\n",
       "       [60, 88, 95, 27,  0,  0,  0,  0,  0,  0],\n",
       "       [76, 88, 92,  3, 60, 27, 71,  0,  0,  0],\n",
       "       [67, 60, 92, 40, 80, 34, 60,  0,  0,  0],\n",
       "       [51, 40, 56, 71, 40, 56,  0,  0,  0,  0],\n",
       "       [67, 40,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [84, 92, 40, 67, 27, 14, 67,  0,  0,  0],\n",
       "       [67, 60, 27,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 7, 88, 92,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [43, 56,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [24, 92, 88, 53,  0,  0,  0,  0,  0,  0],\n",
       "       [88, 56, 71,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [71, 27, 76, 88, 56, 71,  0,  0,  0,  0],\n",
       "       [67, 60, 27,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 7, 43, 67, 60, 71, 92, 88,  7, 88, 86],\n",
       "       [40, 85,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [35, 92, 43, 67, 43, 14, 60,  0,  0,  0],\n",
       "       [67, 92, 40, 40, 84, 14,  0,  0,  0,  0],\n",
       "       [85, 92, 40, 76,  0,  0,  0,  0,  0,  0],\n",
       "       [67, 60, 88, 67,  0,  0,  0,  0,  0,  0],\n",
       "       [ 3, 40, 80, 56, 67, 92, 47,  0,  0,  0],\n",
       "       [ 6,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_char[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
    "X = pad_sequences(maxlen=max_len, \n",
    "                  sequences=X, \n",
    "                  padding='post', \n",
    "                  value=word2idx['PAD'], \n",
    "                  truncating='post')\n",
    "\n",
    "y = [[tag2idx[w[2]] for w in s] for s in sentences]\n",
    "y = pad_sequences(maxlen=max_len, \n",
    "                  sequences=y, \n",
    "                  value=tag2idx['PAD'], \n",
    "                  padding='post',\n",
    "                  truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2,  2,  2,  2,  2,  2, 14,  2,  2,  2,  2,  2, 14,  2,  2,  2,  2,\n",
       "        2, 11,  2,  2,  2,  2,  2,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "        0,  0,  0,  0,  0,  0,  0], dtype=int32)"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "y = [to_categorical(i, num_classes=n_tags+1) for i in y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y, \n",
    "                                                    test_size=0.1, \n",
    "                                                    random_state=2018)\n",
    "\n",
    "X_char_train, X_char_test, y_char_train, y_char_test = train_test_split(X_char,\n",
    "                                                                       y,\n",
    "                                                                       test_size=0.1,\n",
    "                                                                       random_state=2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[44, 60, 27, 47,  0,  0,  0,  0,  0,  0],\n",
       "       [14, 88, 47,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [67, 60, 27,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [71, 40,  3, 80, 76, 27, 56, 67, 14,  0],\n",
       "       [ 7, 27, 92, 27,  0,  0,  0,  0,  0,  0],\n",
       "       [85, 40, 80, 56, 71,  0,  0,  0,  0,  0],\n",
       "       [43, 56,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [67, 60, 27,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 3, 40, 76, 84, 80, 67, 27, 92,  0,  0],\n",
       "       [40, 85,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [50, 72, 61, 33,  0,  0,  0,  0,  0,  0],\n",
       "       [86, 27, 88, 71, 27, 92,  0,  0,  0,  0],\n",
       "       [61, 88, 80, 86,  0,  0,  0,  0,  0,  0],\n",
       "       [61, 27, 47, 27, 14,  0,  0,  0,  0,  0],\n",
       "       [71, 80, 92, 43, 56, 34,  0,  0,  0,  0],\n",
       "       [88,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 3, 92, 40, 14, 14, 42,  4, 40, 92, 71],\n",
       "       [92, 88, 43, 71,  0,  0,  0,  0,  0,  0],\n",
       "       [43, 56,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [55,  3, 80, 88, 71, 40, 92,  0,  0,  0],\n",
       "       [86, 88, 14, 67,  0,  0,  0,  0,  0,  0],\n",
       "       [76, 40, 56, 67, 60,  0,  0,  0,  0,  0],\n",
       "       [ 6,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "       [ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_char_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y_train)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Input\n",
    "from keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional, concatenate\n",
    "from keras_contrib.layers import CRF\n",
    "import keras_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_in = Input(shape=(max_len,), \n",
    "#                name='word_in')\n",
    "# word_emb = Embedding(input_dim=n_words+2, \n",
    "#                      output_dim=20, \n",
    "#                      input_length=max_len,\n",
    "#                      mask_zero=True, \n",
    "#                      name='word_embedding')(word_in)\n",
    "\n",
    "# char_in = Input(shape=(max_len, \n",
    "#                        max_len_char,),\n",
    "#                name='char_in')\n",
    "# char_emb = TimeDistributed(Embedding(input_dim=n_chars+2,\n",
    "#                                      output_dim=10,\n",
    "#                                      input_length=max_len_char,\n",
    "#                                      mask_zero=True,\n",
    "#                                      name='char_embedding'))(char_in)\n",
    "\n",
    "# char_encoder = TimeDistributed(LSTM(units=20, \n",
    "#                                     return_sequences=False,\n",
    "#                                     recurrent_dropout=0.5,\n",
    "#                                     name='char_encoder'))(char_emb)\n",
    "\n",
    "# merged_input = concatenate([word_emb, char_encoder])\n",
    "# model = Bidirectional(LSTM(units=50, \n",
    "#                            return_sequences=True, \n",
    "#                            recurrent_dropout=0.6,\n",
    "#                            name='main_lstm'))(merged_input)\n",
    "\n",
    "# out = TimeDistributed(Dense(n_tags+1, activation='softmax', name='output'))(model)\n",
    "\n",
    "#model = Model(word_in, out)\n",
    "\n",
    "word_input = Input(shape=(max_len,), \n",
    "              name='word_input')\n",
    "\n",
    "word_embedding = Embedding(input_dim=n_words+2,\n",
    "                      output_dim=50, \n",
    "                      input_length=max_len, \n",
    "                      name='word_embedding')(word_input)\n",
    "\n",
    "word_dropout = Dropout(0.1, name='word_dropout')(word_embedding)\n",
    "\n",
    "char_input = Input(shape=(max_len, \n",
    "                       max_len_char,),\n",
    "               name='char_input')\n",
    "char_emb = TimeDistributed(Embedding(input_dim=n_chars+2,\n",
    "                                     output_dim=10,\n",
    "                                     input_length=max_len_char,\n",
    "                                     mask_zero=True,\n",
    "                                     name='char_embedding'))(char_input)\n",
    "\n",
    "char_encoder = TimeDistributed(LSTM(units=20, \n",
    "                                    return_sequences=False,\n",
    "                                    recurrent_dropout=0.5,\n",
    "                                    name='char_encoder'))(char_emb)\n",
    "\n",
    "#dropout = Dropout(0.1, name='dropout')(word_embedding)\n",
    "\n",
    "merged_input = concatenate([word_dropout, char_encoder])\n",
    "\n",
    "blstm = Bidirectional(LSTM(units=100, \n",
    "                           return_sequences=True, \n",
    "                           recurrent_dropout=0.1),\n",
    "                      name='BiLSTM')(merged_input)\n",
    "\n",
    "output = TimeDistributed(Dense(n_tags+1, \n",
    "                               activation='softmax'), \n",
    "                        name='output')(blstm)\n",
    "model = Model(inputs=[word_input, char_input], outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "word_input (InputLayer)         (None, 75)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "char_input (InputLayer)         (None, 75, 10)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "word_embedding (Embedding)      (None, 75, 50)       1759000     word_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_40 (TimeDistri (None, 75, 10, 10)   1000        char_input[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "word_dropout (Dropout)          (None, 75, 50)       0           word_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_41 (TimeDistri (None, 75, 20)       2480        time_distributed_40[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 75, 70)       0           word_dropout[0][0]               \n",
      "                                                                 time_distributed_41[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "BiLSTM (Bidirectional)          (None, 75, 200)      136800      concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "output (TimeDistributed)        (None, 75, 18)       3618        BiLSTM[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 1,902,898\n",
      "Trainable params: 1,902,898\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"acc\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(X_char_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38846 samples, validate on 4317 samples\n",
      "Epoch 1/5\n",
      "38846/38846 [==============================] - 178s 5ms/step - loss: 0.4496 - acc: 0.8977 - val_loss: 0.1616 - val_acc: 0.9548\n",
      "Epoch 2/5\n",
      "38846/38846 [==============================] - 189s 5ms/step - loss: 0.1202 - acc: 0.9651 - val_loss: 0.1162 - val_acc: 0.9651\n",
      "Epoch 3/5\n",
      "38846/38846 [==============================] - 203s 5ms/step - loss: 0.0887 - acc: 0.9730 - val_loss: 0.1047 - val_acc: 0.9685\n",
      "Epoch 4/5\n",
      "38846/38846 [==============================] - 205s 5ms/step - loss: 0.0745 - acc: 0.9767 - val_loss: 0.1040 - val_acc: 0.9688\n",
      "Epoch 5/5\n",
      "38846/38846 [==============================] - 203s 5ms/step - loss: 0.0655 - acc: 0.9790 - val_loss: 0.1025 - val_acc: 0.9691\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([X_train, np.array(X_char_train)], \n",
    "                    np.array(y_train),\n",
    "                    batch_size=64, \n",
    "                    epochs=5, \n",
    "                    validation_split=0.1, \n",
    "                    verbose=1)\n",
    "\n",
    "# history = model.fit([X_train,\n",
    "#                      np.array(X_char_train).reshape((len(X_char_train), max_len, max_len_char))],\n",
    "#                     np.array(y_train).reshape(len(y_train), max_len, 1),\n",
    "#                     batch_size=32, epochs=10, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43163, 75, 10)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X_char_train).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
